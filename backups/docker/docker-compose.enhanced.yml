version: '3.8'

services:
  # Frontend service (unchanged)
  frontend:
    build:
      context: .
      dockerfile: docker/frontend.Dockerfile
      target: ${TARGET_ENV:-development}
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-frontend
    volumes:
      - ./src:/app/src
      - ./public:/app/public
      - ./package.json:/app/package.json
      - ./package-lock.json:/app/package-lock.json
      - ./next.config.js:/app/next.config.js
      - ./tsconfig.json:/app/tsconfig.json
      - ./tailwind.config.js:/app/tailwind.config.js
      - ./postcss.config.js:/app/postcss.config.js
      - ./jest.config.js:/app/jest.config.js
      - ./jest.setup.js:/app/jest.setup.js
      - ./.eslintrc.json:/app/.eslintrc.json
      - /app/node_modules
      - /app/.next
    environment:
      - NODE_ENV=${NODE_ENV:-development}
      - NEXT_PUBLIC_API_URL=http://api_gateway:8000
      - NEXT_PUBLIC_API_SERVICE_URL=http://api_gateway:8000
      - NEXT_TELEMETRY_DISABLED=1
      - PORT=3000
    ports:
      - "3000:3000"
    command: npm run ${NPM_COMMAND:-dev}
    healthcheck:
      test: ["CMD-SHELL", "node -e \"const http = require('http'); const options = { hostname: 'localhost', port: 3000, path: '/api/health', method: 'GET' }; const req = http.request(options, (res) => { if (res.statusCode === 200) { process.exit(0); } else { process.exit(1); } }); req.on('error', () => { process.exit(1); }); req.end();\""]
      interval: ${HEALTH_CHECK_INTERVAL:-15s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-40s}
    depends_on:
      api_gateway:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 2G
        reservations:
          memory: 1G

  # API Gateway - Routes requests to appropriate services
  api_gateway:
    build:
      context: .
      dockerfile: docker/api_gateway.Dockerfile
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-gateway
    ports:
      - "8000:8000"
    environment:
      - QUESTIONNAIRE_SERVICE_URL=http://questionnaire_agent:5001
      - RECTIFICATION_SERVICE_URL=http://rectification_engine:5002
      - VALIDATION_SERVICE_URL=http://validation_engine:5003
      - CHART_SERVICE_URL=http://chart_generator:5004
      - REDIS_URL=redis://redis:6379/0
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: ${HEALTH_CHECK_INTERVAL:-15s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-30s}
    depends_on:
      redis:
        condition: service_healthy
      questionnaire_agent:
        condition: service_healthy
      rectification_engine:
        condition: service_healthy
      validation_engine:
        condition: service_healthy
      chart_generator:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Questionnaire Agent - Handles dynamic questionnaire generation
  questionnaire_agent:
    build:
      context: .
      dockerfile: docker/questionnaire_agent.Dockerfile
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-questionnaire
    volumes:
      - ./ai_service:/app/ai_service
      - ./questionnaire_templates:/app/templates
      - questionnaire_cache:/app/cache
    environment:
      - PYTHONUNBUFFERED=1
      - ENVIRONMENT=${APP_ENV:-development}
      - APP_ENV=${APP_ENV:-development}
      - REDIS_URL=redis://redis:6379/1
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_API_KEY_P=${OPENAI_API_KEY_P:-}
      - OPENAI_API_KEY_DEV=${OPENAI_API_KEY_DEV:-}
      - OPENAI_API_KEY_DEV_P=${OPENAI_API_KEY_DEV_P:-}
      - API_TIMEOUT=${API_TIMEOUT:-60}
      - CACHE_EXPIRY=${CACHE_EXPIRY:-3600}
      - CACHE_DIR=/app/cache
      - OPENAI_MODEL_QUESTIONNAIRE=${OPENAI_MODEL_QUESTIONNAIRE:-gpt-4-turbo}
    ports:
      - "5001:5001"
    command: python -m uvicorn ai_service.questionnaire_service:app --host 0.0.0.0 --port 5001 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5001/health"]
      interval: ${HEALTH_CHECK_INTERVAL:-15s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-30s}
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Rectification Engine - Handles birth time rectification calculations
  rectification_engine:
    build:
      context: .
      dockerfile: docker/rectification_engine.Dockerfile
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-rectification
    volumes:
      - ./ai_service:/app/ai_service
      - ephemeris_data:/app/ephemeris
      - rectification_cache:/app/cache
    environment:
      - PYTHONUNBUFFERED=1
      - ENVIRONMENT=${APP_ENV:-development}
      - APP_ENV=${APP_ENV:-development}
      - REDIS_URL=redis://redis:6379/2
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - SWISSEPH_PATH=/app/ephemeris
      - GPU_ENABLED=${GPU_ENABLED:-false}
      - GPU_MEMORY_FRACTION=0.7
    ports:
      - "5002:5002"
    command: python -m uvicorn ai_service.rectification_service:app --host 0.0.0.0 --port 5002 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5002/health"]
      interval: ${HEALTH_CHECK_INTERVAL:-15s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-30s}
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Validation Engine - Validates rectification results and calculates confidence
  validation_engine:
    build:
      context: .
      dockerfile: docker/validation_engine.Dockerfile
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-validation
    volumes:
      - ./ai_service:/app/ai_service
      - ./validation_rules:/app/rules
      - validation_cache:/app/cache
    environment:
      - PYTHONUNBUFFERED=1
      - ENVIRONMENT=${APP_ENV:-development}
      - APP_ENV=${APP_ENV:-development}
      - REDIS_URL=redis://redis:6379/3
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_API_KEY_P=${OPENAI_API_KEY_P:-}
      - OPENAI_API_KEY_DEV=${OPENAI_API_KEY_DEV:-}
      - OPENAI_API_KEY_DEV_P=${OPENAI_API_KEY_DEV_P:-}
      - API_TIMEOUT=${API_TIMEOUT:-60}
      - CACHE_EXPIRY=${CACHE_EXPIRY:-3600}
      - CACHE_DIR=/app/cache
      - OPENAI_MODEL_EXPLANATION=${OPENAI_MODEL_EXPLANATION:-gpt-4-turbo}
    ports:
      - "5003:5003"
    command: python -m uvicorn ai_service.validation_service:app --host 0.0.0.0 --port 5003 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5003/health"]
      interval: ${HEALTH_CHECK_INTERVAL:-15s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-30s}
    depends_on:
      redis:
        condition: service_healthy
      rectification_engine:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Chart Generator - Generates astrological charts and visualizations
  chart_generator:
    build:
      context: .
      dockerfile: docker/chart_generator.Dockerfile
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-chart
    volumes:
      - ./ai_service:/app/ai_service
      - ephemeris_data:/app/ephemeris
      - chart_cache:/app/cache
    environment:
      - PYTHONUNBUFFERED=1
      - ENVIRONMENT=${APP_ENV:-development}
      - APP_ENV=${APP_ENV:-development}
      - REDIS_URL=redis://redis:6379/4
      - LOG_LEVEL=${LOG_LEVEL:-INFO}
      - SWISSEPH_PATH=/app/ephemeris
      - OPENAI_API_KEY=${OPENAI_API_KEY:-}
      - OPENAI_API_KEY_P=${OPENAI_API_KEY_P:-}
      - OPENAI_API_KEY_DEV=${OPENAI_API_KEY_DEV:-}
      - OPENAI_API_KEY_DEV_P=${OPENAI_API_KEY_DEV_P:-}
      - API_TIMEOUT=${API_TIMEOUT:-60}
      - CACHE_EXPIRY=${CACHE_EXPIRY:-3600}
      - CACHE_DIR=/app/cache
      - OPENAI_MODEL_VISUALIZATION=${OPENAI_MODEL_VISUALIZATION:-gpt-4-turbo}
    ports:
      - "5004:5004"
    command: python -m uvicorn ai_service.chart_service:app --host 0.0.0.0 --port 5004 --reload
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:5004/health"]
      interval: ${HEALTH_CHECK_INTERVAL:-15s}
      timeout: ${HEALTH_CHECK_TIMEOUT:-10s}
      retries: ${HEALTH_CHECK_RETRIES:-3}
      start_period: ${HEALTH_CHECK_START_PERIOD:-30s}
    depends_on:
      redis:
        condition: service_healthy
    restart: always
    deploy:
      resources:
        limits:
          memory: 1G
        reservations:
          memory: 512M

  # Redis service (unchanged)
  redis:
    image: redis:7.2-alpine
    container_name: ${CONTAINER_PREFIX:-birth-rectifier}-redis
    ports:
      - "6379:6379"
    volumes:
      - ./docker/redis.conf:/usr/local/etc/redis/redis.conf:ro
      - redis_data:/data
      - ./docker/redis/log:/var/log/redis
    command: ${REDIS_COMMAND:-redis-server /usr/local/etc/redis/redis.conf}
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 10s
      retries: 10
      start_period: 15s
    restart: always
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

volumes:
  redis_data:
    driver: local
  ephemeris_data:
    driver: local
  questionnaire_cache:
    driver: local
  rectification_cache:
    driver: local
  validation_cache:
    driver: local
  chart_cache:
    driver: local
